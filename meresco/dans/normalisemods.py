# -*- coding: utf-8 -*-
## begin license ##
#
# Gemeenschappelijke Metadata Harvester (GMH) data extractie en OAI service
#
# Copyright (C) 2025 Koninklijke Bibliotheek (KB) https://www.kb.nl
# Copyright (C) 2025 Seecr (Seek You Too B.V.) https://seecr.nl
#
# This file is part of "GMH-Meresco"
#
# "GMH-Meresco" is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 2 of the License, or
# (at your option) any later version.
#
# "GMH-Meresco" is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with "GMH-Meresco"; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
#
## end license ##

from lxml import etree
from lxml.etree import (
    parse,
    XMLSchema,
    XMLSchemaParseError,
    _ElementTree,
    tostring,
    fromstring,
)
from copy import deepcopy
from io import BytesIO
from meresco.components.xml_generic.validate import ValidateException
from meresco.xml.namespaces import namespaces

from .xmlvalidator import formatExceptionLine
from dateutil.parser import parse as parseDate
from datetime import *
from .normalisedidl import XML_ENCODING
from meresco.dans.uiaconverter import UiaConverter

from . import commons as comm

# Schema validatie:
from os.path import abspath, dirname, join

# This component handles ADD messages only.
# It will try to convert the supplied data (KNAWLong) from the 'metadata' part into KNAWshort. All other parts and data formats are ignored (blocked).
# If it fails in doing so, it will block (NOT pass) the ADD message.
# Returns: xml-string!


# Taken from: EduStandaard Semantiek, tabel 1 en 2.
GENRES_SEMANTIEK = {
    "article": "info:eu-repo/semantics/article",
    "bachelorthesis": "info:eu-repo/semantics/bachelorThesis",
    "masterthesis": "info:eu-repo/semantics/masterThesis",
    "doctoralthesis": "info:eu-repo/semantics/doctoralThesis",
    "book": "info:eu-repo/semantics/book",
    "bookpart": "info:eu-repo/semantics/bookPart",
    "review": "info:eu-repo/semantics/review",
    "conferenceobject": "info:eu-repo/semantics/conferenceObject",
    "lecture": "info:eu-repo/semantics/lecture",
    "workingpaper": "info:eu-repo/semantics/workingPaper",
    "preprint": "info:eu-repo/semantics/preprint",
    "report": "info:eu-repo/semantics/report",
    "annotation": "info:eu-repo/semantics/annotation",
    "contributiontoperiodical": "info:eu-repo/semantics/contributionToPeriodical",
    "patent": "info:eu-repo/semantics/patent",
    "other": "info:eu-repo/semantics/other",
    "reportpart": "info:eu-repo/semantics/reportPart",
    "bookreview": "info:eu-repo/semantics/bookReview",
    "researchproposal": "info:eu-repo/semantics/researchProposal",
    "studentthesis": "info:eu-repo/semantics/studentThesis",
    "technicaldocumentation": "info:eu-repo/semantics/technicalDocumentation",
    "semantics/conferenceposter": "info:eu-repo/semantics/conferencePoster",
    "conferenceproceedings": "info:eu-repo/semantics/conferenceProceedings",
    "conferenceitemnotinproceedings": "info:eu-repo/semantics/conferenceItemNotInProceedings",
    "semantics/conferencepaper": "info:eu-repo/semantics/conferencePaper",
    "conferenceitem": "http://purl.org/eprint/type/ConferenceItem",
    "type/conferenceposter": "http://purl.org/eprint/type/ConferencePoster",
    "type/conferencepaper": "http://purl.org/eprint/type/ConferencePaper",
}


MODS_VERSION = "3.6"
STR_MODS = "MODS:"

# Taken from: https://www.loc.gov/marc/relators/relacode.html (Updated: 2025-02-10)
MARC_ROLES = [
    "abr",
    "acp",
    "act",
    "adi",
    "adp",
    "aft",
    "anc",
    "anl",
    "anm",
    "ann",
    "ant",
    "ape",
    "apl",
    "app",
    "aqt",
    "arc",
    "ard",
    "arr",
    "art",
    "asg",
    "asn",
    "ato",
    "att",
    "auc",
    "aud",
    "aue",
    "aui",
    "aup",
    "aus",
    "aut",
    "bdd",
    "bjd",
    "bka",
    "bkd",
    "bkp",
    "blw",
    "bnd",
    "bpd",
    "brd",
    "brl",
    "bsl",
    "cad",
    "cas",
    "ccp",
    "chr",
    "clb",
    "cli",
    "cll",
    "clr",
    "clt",
    "cmm",
    "cmp",
    "cmt",
    "cnd",
    "cng",
    "cns",
    "coe",
    "col",
    "com",
    "con",
    "cop",
    "cor",
    "cos",
    "cot",
    "cou",
    "cov",
    "cpc",
    "cpe",
    "cph",
    "cpl",
    "cpt",
    "cre",
    "crp",
    "crr",
    "crt",
    "csl",
    "csp",
    "cst",
    "ctb",
    "cte",
    "ctg",
    "ctr",
    "cts",
    "ctt",
    "cur",
    "cwt",
    "dbd",
    "dbp",
    "dfd",
    "dfe",
    "dft",
    "dgc",
    "dgg",
    "dgs",
    "dis",
    "djo",
    "dln",
    "dnc",
    "dnr",
    "dpc",
    "dpt",
    "drm",
    "drt",
    "dsr",
    "dst",
    "dtc",
    "dte",
    "dtm",
    "dto",
    "dub",
    "edc",
    "edd",
    "edm",
    "edt",
    "egr",
    "elg",
    "elt",
    "eng",
    "enj",
    "etr",
    "evp",
    "exp",
    "fac",
    "fds",
    "fld",
    "flm",
    "fmd",
    "fmk",
    "fmo",
    "fmp",
    "fnd",
    "fon",
    "fpy",
    "frg",
    "gdv",
    "gis",
    "-gr",
    "his",
    "hnr",
    "hst",
    "ill",
    "ilu",
    "ink",
    "ins",
    "inv",
    "isb",
    "itr",
    "ive",
    "ivr",
    "jud",
    "jug",
    "lbr",
    "lbt",
    "ldr",
    "led",
    "lee",
    "lel",
    "len",
    "let",
    "lgd",
    "lie",
    "lil",
    "lit",
    "lsa",
    "lse",
    "lso",
    "ltg",
    "ltr",
    "lyr",
    "mcp",
    "mdc",
    "med",
    "mfp",
    "mfr",
    "mka",
    "mod",
    "mon",
    "mrb",
    "mrk",
    "msd",
    "mte",
    "mtk",
    "mup",
    "mus",
    "mxe",
    "nan",
    "nrt",
    "onp",
    "opn",
    "org",
    "orm",
    "osp",
    "oth",
    "own",
    "pad",
    "pan",
    "pat",
    "pbd",
    "pbl",
    "pdr",
    "pfr",
    "pht",
    "plt",
    "pma",
    "pmn",
    "pnc",
    "pop",
    "ppm",
    "ppt",
    "pra",
    "prc",
    "prd",
    "pre",
    "prf",
    "prg",
    "prm",
    "prn",
    "pro",
    "prp",
    "prs",
    "prt",
    "prv",
    "pta",
    "pte",
    "ptf",
    "pth",
    "ptt",
    "pup",
    "rap",
    "rbr",
    "rcd",
    "rce",
    "rcp",
    "rdd",
    "red",
    "ren",
    "res",
    "rev",
    "rpc",
    "rps",
    "rpt",
    "rpy",
    "rse",
    "rsg",
    "rsp",
    "rsr",
    "rst",
    "rth",
    "rtm",
    "rxa",
    "sad",
    "sce",
    "scl",
    "scr",
    "sde",
    "sds",
    "sec",
    "sfx",
    "sgd",
    "sgn",
    "sht",
    "sll",
    "sng",
    "spk",
    "spn",
    "spy",
    "srv",
    "std",
    "stg",
    "stl",
    "stm",
    "stn",
    "str",
    "swd",
    "tad",
    "tau",
    "tcd",
    "tch",
    "ths",
    "tld",
    "tlg",
    "tlh",
    "tlp",
    "trc",
    "trl",
    "tyd",
    "tyg",
    "uvp",
    "vac",
    "vdg",
    "vfx",
    "voc",
    "wac",
    "wal",
    "wam",
    "wat",
    "wdc",
    "wde",
    "wfs",
    "wft",
    "win",
    "wit",
    "wpr",
    "wst",
    "wts",
]
LOGGER1 = " is not a valid RFC3066 language code."
LOGGER2 = "Found unknown extension (no EDUstandaard)."
LOGGER3 = "Unknown identifier authority: %s in /mods:extension/dai:daiList; Identifier for this authority will not be processed."
LOGGER4 = "Complete <m:name> element was removed: Could not find valid <m:roleTerm> and/or <m:namePart> element(s)"

EXCEPTION1 = "Mandatory MODS metadata not found in DIDL Item."
EXCEPTION2 = "Mandatory MODS titleInfo not found."
EXCEPTION3 = "MODS titleInfo/title has empty value."
EXCEPTION4 = "MODS invalid role macrelator: "
EXCEPTION5 = "Mandatory MODS name not found."
EXCEPTION6 = "No valid MODS genre found."
EXCEPTION7 = "Mandatory MODS originInfo/dateIssued not found."


# , ('hbo/hboMODSextension.xsd', 'self::hbo:hbo')
# ('xml-schema location', 'xpath to root', 'schema location'):
mods_edu_extentions = [
    (
        "dai/dai-extension.xsd",
        "self::dai:daiList",
        "info:eu-repo/dai http://purl.org/REP/standards/dai-extension.xsd",
    ),
    (
        "gal/gal-extension.xsd",
        "self::gal:grantAgreementList",
        "info:eu-repo/grantAgreement http://purl.org/REP/standards/gal-extension.xsd",
    ),
    (
        "wmp/wmp-extension.xsd",
        "self::wmp:rights",
        "http://www.surfgroepen.nl/werkgroepmetadataplus http://purl.org/REP/standards/wmp-extension.xsd",
    ),
]

## Do not list "extension" here. So it will be removed by default. <extension> is handeled by a different function.
mods_edu_tlelements = [
    "titleInfo",
    "relatedItem",
    "name",
    "language",
    "typeOfResource",
    "genre",
    "abstract",
    "identifier",
    "classification",
    "subject",
    "originInfo",
]
# Skipped tl elements because not part of EduStandaard: , ["location", "note", "physicalDescription", "recordInfo", "tableOfContents", "targetAudience"]


class NormaliseMODS(UiaConverter):
    """A class that normalizes MODS metadata to the EduStandaard applicationprofile"""

    def __init__(self, fromKwarg, toKwarg=None, name=None, nsMap=None):
        UiaConverter.__init__(self, name=name, fromKwarg=fromKwarg, toKwarg=toKwarg)
        self._nsMap = namespaces.copyUpdate(nsMap or {})
        self._bln_success = False
        self._edu_extension_schemas = []

        ## Fill the schemas list for later use:
        for schemaPath, xPad, s_loc in mods_edu_extentions:
            print("schema init:", schemaPath, xPad, s_loc)
            try:
                self._edu_extension_schemas.append(
                    (
                        XMLSchema(
                            parse(join(dirname(abspath(__file__)), "xsd/" + schemaPath))
                        ),
                        xPad,
                        s_loc,
                    )
                )
            except XMLSchemaParseError as e:
                print("XMLSchemaParseError.", e.error_log.last_error)
                raise

    def _convert(self, lxmlNode):
        if not type(lxmlNode) == _ElementTree:
            return lxmlNode
        self._bln_success = False
        self._bln_hasTypOfResource = False

        # start conversion: Look for <part name="normdoc"> in the document:
        didl_tree = fromstring(
            lxmlNode.xpath(
                "//document:document/document:part[@name='normdoc']/text()",
                namespaces=self._nsMap,
            )[0]
        )  # TODO: import 'normdoc" string.
        norm_didl_tree = self._normaliseRecord(didl_tree)

        if norm_didl_tree != None:
            self._bln_success = True

        normdocpart = lxmlNode.xpath(
            "//document:document/document:part[@name='normdoc']", namespaces=self._nsMap
        )
        if normdocpart:
            normdocpart[0].text = tostring(
                norm_didl_tree, encoding=XML_ENCODING
            ).decode(XML_ENCODING)

        return lxmlNode

    def _normaliseRecord(self, lxmlNode):
        # MODS normalisation in 4 steps:
        # 1. Get Mods from the lxmlNode.
        # 2. Normalize it
        # 3. Put it back in place.
        # 4. return the lxmlNode containing the normalized MODS.

        # 1: Get Mods from the lxmlNode:
        lxmlMODS = lxmlNode.xpath("(//mods:mods)[1]", namespaces=self._nsMap)

        ## Our normalisation functions to call:
        modsFunctions = [self._convertFullMods2GHMods]

        if len(lxmlMODS) > 0:
            # 2: Normalize it
            norm_mods = b""
            for function in modsFunctions:
                norm_mods += function(lxmlMODS[0])

            print("NORM_MODS", norm_mods)
            # 3: Put it back in DIDL/place:
            lxmlMODS[0].getparent().replace(
                lxmlMODS[0], etree.parse(BytesIO(norm_mods)).getroot()
            )

        else:  # This should never happen @runtime: record should have been validated up front...
            raise ValidateException(formatExceptionLine(EXCEPTION1, prefix=STR_MODS))

        # 4: Return the lxmlNode containing the normalized MODS:
        # print(etree.tostring(lxmlNode, pretty_print=True))
        return lxmlNode

    def _convertFullMods2GHMods(self, lxmlMODSNode):
        returnxml = ""
        ## We need a deepcopy, otherwise we'll modify the lxmlnode by reference!!
        e_modsroot_copy = deepcopy(lxmlMODSNode)

        ## Check if version 3.4 was supplied: correct otherwise.
        self._normalizeModsVersion(e_modsroot_copy)

        ## Valideer en normaliseer alle extension tags in 1 tag en bewaar deze voor later....
        e_temp_extensions = self._getValidModsExtension(e_modsroot_copy)
        ## LET OP: Alle <extension> tags worden hieronder verwijdert doordat _tlExtension() 'None' terug geeft.

        ## Valideer en normaliseer alle titleInfo tags:
        self._normalizeTitleinfo(e_modsroot_copy)

        ## Valideer en normaliseer alle <name> tags op e_modsrppt_copy...
        self._validateNames(e_modsroot_copy)
        ## LET OP: Alle <name> tags worden hieronder verwijderd doordat _tlNames() 'None' terug geeft.

        ## Normaliseer alle Genre tags...
        self._validateGenre(e_modsroot_copy)

        ## Check for EduStandaard mandatory originInfo tag:
        self._checkOriginInfoDateIssued(e_modsroot_copy)

        ## Itereer over ALLE toplevel elementen:
        for child in e_modsroot_copy.iterchildren():
            for (
                tlelement
            ) in mods_edu_tlelements:  ## Iterate over all top level elements...
                if child.tag == ("{%s}" + tlelement) % self._nsMap["mods"]:
                    ## Call normalisation function on current child:
                    returnChild = eval("self._tl" + tlelement.capitalize())(child)
                    if returnChild is None:
                        e_modsroot_copy.remove(child)
                    else:
                        child.getparent().replace(child, returnChild)
                    break
            else:  # Wordt alleen geskipped als ie uit 'break' komt...
                e_modsroot_copy.remove(child)
        ## Append our <extension> child elements to the root:
        if e_temp_extensions is not None:
            for child in e_temp_extensions.iterfind(
                ("{%s}extension") % self._nsMap["mods"]
            ):
                if child.xpath(
                    "boolean(count(self::mods:extension/dai:daiList))",
                    namespaces=self._nsMap,
                ):  # = daiList extension:
                    for daiid in child.iterfind(
                        (".//{%s}identifier") % self._nsMap["dai"]
                    ):
                        self._addDaiFromModExtension(
                            e_modsroot_copy,
                            daiid.get("IDref"),
                            daiid.get("authority"),
                            daiid.text,
                        )
                else:
                    e_modsroot_copy.append(child)

        ## Nornmalize xml:ID and xml:IDref: Combined format will not validate if xml:ID's are not unique:
        for idname in e_modsroot_copy.findall(
            (".//{%s}name[@ID]") % self._nsMap["mods"]
        ):
            origID = idname.get("ID")
            # Check if this ID is in use by a mods:extension:
            extensions = e_modsroot_copy.xpath(
                "//mods:extension/descendant::*[@IDref='" + origID + "']",
                namespaces=self._nsMap,
            )
            if len(extensions) > 0:
                for extension in extensions:  # if so, rename both ID and IDref:
                    extension.attrib["IDref"] = "gmh_" + origID
                idname.attrib["ID"] = "gmh_" + origID
            else:  # Remove name@ID reference not in use (any more).
                idname.attrib.pop("ID", None)

        ## Append one typeOfResource to root, if it does not exist:
        if not self._bln_hasTypOfResource:
            self._addTypeOfResource(e_modsroot_copy)

        ## We'll add the MODS node to a new custom element and remove it again, so that lxml will use the mods prefix used in the namespacemap.
        ## Otherwise default namespaces may be used for MODS...
        root = etree.Element("{" + self._nsMap["mods"] + "}temp", nsmap=self._nsMap)
        root.append(e_modsroot_copy)

        ## Some namespaces may not be in use anymore after normalisation: remove them...
        etree.cleanup_namespaces(root)

        returnxml = tostring(
            root.find(("{%s}mods") % self._nsMap["mods"]),
            pretty_print=True,
            encoding=XML_ENCODING,
        )
        # returnxml = etree.tostring(e_modsroot_copy, pretty_print=True, encoding=XML_ENCODING)
        # print returnxml
        return returnxml

    ## mods version:
    def _normalizeModsVersion(self, e_modsroot):
        # We'll always normalize to MODS_VERSION and proper schemalocation:
        e_modsroot.set("version", MODS_VERSION)
        e_modsroot.set(
            "{http://www.w3.org/2001/XMLSchema-instance}schemaLocation",
            "http://www.loc.gov/mods/v3 http://www.loc.gov/standards/mods/v3/mods-"
            + MODS_VERSION.replace(".", "-")
            + ".xsd",
        )
        return e_modsroot

    ## titleInfo:
    def _normalizeTitleinfo(self, modsNode):
        ## Select all titleInfo's
        hasTitleInfo = False
        for child in modsNode.iterfind(("{%s}titleInfo") % self._nsMap["mods"]):
            hasTitleInfo = True
            if not self._isValidTitleInfoTag(child):
                modsNode.remove(child)
        if not hasTitleInfo:
            raise ValidateException(formatExceptionLine(EXCEPTION2, prefix=STR_MODS))

    ## Checks if element exists: it is not checked for if completely missing from mods.
    def _checkOriginInfoDateIssued(self, modsNode):
        if (
            len(
                modsNode.xpath(
                    "//mods:mods/mods:originInfo/mods:dateIssued",
                    namespaces=self._nsMap,
                )
            )
            <= 0
        ):
            raise ValidateException(formatExceptionLine(EXCEPTION7, prefix=STR_MODS))

    def _isValidTitleInfoTag(self, lxmlNode):
        for title in lxmlNode.iterfind(("{%s}title") % self._nsMap["mods"]):
            if not title.text or not title.text.strip():
                raise ValidateException(
                    formatExceptionLine(EXCEPTION3, prefix=STR_MODS)
                )
        for subtitle in lxmlNode.iterfind(("{%s}subTitle") % self._nsMap["mods"]):
            if not subtitle.text or not subtitle.text.strip():
                subtitle.getparent().remove(subtitle)
        return True

    def _tlTitleinfo(self, childNode):
        ## Pass thru all (normalized) titleInfo nodes...
        return childNode

    ## Name:
    def _validateNames(self, modsNode):
        for name in modsNode.iterfind(("{%s}name") % self._nsMap["mods"]):
            for roleterm in name.iterfind((".//{%s}roleTerm") % self._nsMap["mods"]):
                if roleterm.text:
                    roleterm.text = roleterm.text.strip()
            role = name.xpath(
                "self::mods:name/mods:role/mods:roleTerm[@type='code' and @authority='marcrelator']/text()",
                namespaces=self._nsMap,
            )
            for namepart in name.iterfind(("{%s}namePart") % self._nsMap["mods"]):
                if (
                    not namepart.text or not namepart.text.strip()
                ):  # Remove empty nameparts
                    name.remove(namepart)
            if (
                not role
                or len(role) < 1
                or name.find(("{%s}namePart") % self._nsMap["mods"]) is None
            ):  ## Geen roleterm gevonden, of lege string voor type code en authority marcrelator, of geen nameParts: Verwijder dit name element:
                modsNode.remove(name)
                self.do.logMsg(self._uploadid, LOGGER4, prefix=STR_MODS)
            elif len(role) > 0 and not self.__isValidRoleTerm(role[0]):
                raise ValidateException(
                    formatExceptionLine(EXCEPTION4 + role[0], prefix=STR_MODS)
                )
        if len(modsNode.xpath("//mods:mods/mods:name", namespaces=self._nsMap)) <= 0:
            raise ValidateException(formatExceptionLine(EXCEPTION5, prefix=STR_MODS))

    def __isValidRoleTerm(self, str_roleTerm):
        return True if str_roleTerm.strip() in MARC_ROLES else False

    def _tlName(self, childNode):
        ## Pass thru all (normalized) name nodes...
        return childNode

    ## Language:
    def _tlLanguage(self, childNode):
        for langterm_node in childNode.iterfind(
            "{" + self._nsMap.get("mods") + "}languageTerm"
        ):  # Check if languageTerm element is valid orelse remove it.
            if (
                langterm_node.get("type") == "code"
            ):  # Do not check for authority: we'll set it for you if you provided a valid rfc3066 code.
                if comm.isValidRFC3066(langterm_node.text):
                    langterm_node.set("authority", "rfc3066")
                else:
                    self.do.logMsg(
                        self._uploadid,
                        (langterm_node.text if langterm_node.text is not None else "")
                        + LOGGER1,
                        prefix=STR_MODS,
                    )
                    childNode.remove(langterm_node)
            elif langterm_node.get("type") == "text":
                langterm_node.attrib.pop("authority", None)
        if len(list(childNode)) == 0:
            return None
        else:
            return childNode

    ## Genre:
    def _validateGenre(self, modsNode):

        fqGenre = None
        bln_hasValid = False
        ## Loop all 'genre' elements as separate nodes:
        for genre in modsNode.iterfind("{" + self._nsMap.get("mods") + "}genre"):

            for key, value in GENRES_SEMANTIEK.items():
                if (
                    genre.text and genre.text.strip().lower().find(key) >= 0
                ):  # found a (lowercased) genre
                    fqGenre = value
                    break

            if fqGenre is not None and not bln_hasValid:
                bln_hasValid = True
                genre.text = fqGenre
            else:
                modsNode.remove(genre)

        if not bln_hasValid:
            raise ValidateException(formatExceptionLine(EXCEPTION6, prefix=STR_MODS))

    def _tlGenre(self, childNode):
        return childNode  ## Genres have been normalised already by _validateGenre()

    ## OriginInfo:
    def _tlOrigininfo(self, childNode):
        hasDateIssued = False
        ## Select all children from originInfo having 'encoding' attribute:
        children = childNode.xpath(
            "self::mods:originInfo/child::*[@encoding='w3cdtf' or @encoding='iso8601']",
            namespaces=self._nsMap,
        )
        if len(children) > 0:
            for child in children:
                if self._validateISO8601(child.text):
                    child.text = self._granulateDate(child.text)
                    child.set("encoding", "w3cdtf")
                    if child.tag == ("{%s}dateIssued") % self._nsMap["mods"]:
                        hasDateIssued = True
                else:
                    child.getparent().remove(child)
        if not hasDateIssued:
            raise ValidateException(formatExceptionLine(EXCEPTION7, prefix=STR_MODS))

        for child in childNode.xpath(
            "self::mods:originInfo/mods:publisher", namespaces=self._nsMap
        ):
            if not child.text or not child.text.strip():
                child.getparent().remove(child)

        return childNode if len(childNode) > 0 else None

    def _validateISO8601(self, datestring):
        ## See: http://labix.org/python-dateutil
        if datestring is None:
            return False

        try:
            parseDate(datestring, ignoretz=True, fuzzy=True)
        except ValueError:
            return False
        return True

    def _granulateDate(self, str_date):
        """returns only date parts that are succesfully parsed."""
        di_1 = parseDate(
            str_date, ignoretz=True, fuzzy=True, default=datetime(1900, 12, 28, 0, 0)
        )  # 1900-12-28 default year, month and day. (day 28 exists for every month:-)
        di_2 = parseDate(
            str_date, ignoretz=True, fuzzy=True, default=datetime(2000, 0o1, 0o1, 0, 0)
        )  # 2000-01-01 default year, month and day.

        ## Parsed date with no defaults used:
        if str(di_1.date()) == str(di_2.date()):
            return str(di_1.date())  # Dates are the same: date is parsed completely.

        ## Check for dft day and month:
        if (
            di_1.date().day != di_2.date().day
            and di_1.date().month != di_2.date().month
        ):
            return str(di_1.date().year)  # Only year has been parsed succesfully.
        if (
            di_1.date().day != di_2.date().day
            and di_1.date().month == di_2.date().month
        ):
            return ("%s-%s") % (
                di_1.date().year,
                di_1.date().month,
            )  # Only year and month have been parsed succesfully.

    ## Location:
    #    def _tlLocation(self, childNode):
    #        for url in childNode.iterfind(('{%s}url') % self._nsMap['mods']):
    #            if not self._isURL(url.text): childNode.remove(url)
    #        return childNode if len(childNode) > 0 else None

    ## Abstract:
    def _tlAbstract(self, childNode):
        ## Pass thru all abstract nodes: xml-schema validation of MODS has already taken place...
        # We need to remove all 'attributes' except xml:lang (EduStandaard)...
        for k, v in childNode.attrib.items():
            if k != "{http://www.w3.org/XML/1998/namespace}lang":
                del childNode.attrib[k]
        return childNode

    ## PhysicalDescription:
    def _tlPhysicaldescription(self, childNode):  # Extent check, skip otherwise...
        pages = childNode.xpath(
            "self::mods:physicalDescription/mods:extent/text()", namespaces=self._nsMap
        )
        if len(pages) <= 0:
            return childNode
        elif not pages[0].strip():
            return None
        return childNode

    def _removeNamespace(self, tagName):
        return "}" in tagName and tagName.split("}")[1] or tagName

    ## RelatedItem:
    def _tlRelateditem(self, childNode):
        # 1: Remove all non-Edustandaard 'types' (only @type=host):
        type_attr = childNode.get("type")
        if type_attr is None or (
            type_attr is not None and not type_attr.strip() in ["host"]
        ):  # ['preceding', 'host', 'succeeding', 'series', 'otherVersion']
            return None

        # 2: Remove all NON-eduStandaard top-level elements:
        allowedlist = list(mods_edu_tlelements)
        allowedlist.append("part")  # preserve <part> elements.
        for relitem_child in childNode.iterchildren():
            if not self._removeNamespace(relitem_child.tag) in allowedlist:
                childNode.remove(relitem_child)

        # 3: Check if <start>, <end> and <total> tags are integers:
        children = childNode.xpath(
            "self::mods:relatedItem/mods:part/mods:extent[@unit='page']/child::*",
            namespaces=self._nsMap,
        )
        if len(children) > 0:
            for child in children:  # <start>, <end>, <total> tags...
                if child.tag in [
                    ("{%s}start") % self._nsMap["mods"],
                    ("{%s}end") % self._nsMap["mods"],
                    ("{%s}total") % self._nsMap["mods"],
                ] and not comm.isInt(child.text):
                    ouder = child.getparent()
                    ouder.remove(child)
                    if len(ouder) == 0:
                        ouder.getparent().remove(ouder)

        # 4: Normalize <part><date encoding=""> tag:
        children = childNode.xpath(
            "self::mods:relatedItem/mods:part/mods:date", namespaces=self._nsMap
        )
        if len(children) > 0:
            for child in children:
                child.getparent().remove(child)

        # 5: Normalize date (see also originInfo)
        # Select all children from originInfo having 'encoding' attribute:
        children = childNode.xpath(
            "self::mods:relatedItem/mods:originInfo/child::*[@encoding='w3cdtf' or @encoding='iso8601']",
            namespaces=self._nsMap,
        )
        if len(children) > 0:
            for child in children:
                if self._validateISO8601(child.text):
                    child.text = self._granulateDate(child.text)
                    child.set("encoding", "w3cdtf")
                else:
                    child.getparent().remove(child)

        # 6: Clean some empty elements
        for child in childNode.xpath(
            "self::mods:relatedItem/mods:originInfo/mods:publisher",
            namespaces=self._nsMap,
        ):
            if not child.text or not child.text.strip():
                child.getparent().remove(child)

        for subtitle in childNode.xpath(
            "self::mods:relatedItem/mods:titleInfo/mods:subTitle",
            namespaces=self._nsMap,
        ):
            if not subtitle.text or not subtitle.text.strip():
                subtitle.getparent().remove(subtitle)

        for detailchild in childNode.xpath(
            "self::mods:relatedItem/mods:part/mods:detail/child::*",
            namespaces=self._nsMap,
        ):
            if not detailchild.text or not detailchild.text.strip():
                ouder = detailchild.getparent()
                ouder.remove(detailchild)
                if len(ouder) == 0:
                    ouder.getparent().remove(ouder)

        return childNode if len(childNode) > 0 else None

    ## Part (relatedItem):
    def _isValidPart(self, partNode):
        return False

    ## TypeOfResource:
    def _tlTypeofresource(self, childNode):
        # KB/Gijs 16-juni'23: de (KB) validatie loopt vast op een leeg element: <mods:TypeOfResource/>:

        # Returns (xml-validated) term (other than 'text' allowed), skips empty elements:
        # if not self._bln_hasTypOfResource:
        #     if not childNode.text or not childNode.text.strip():
        #         return None
        #     else:
        #         self._bln_hasTypOfResource = True
        #         return childNode

        # However, for now, we will never return a node, so it will be added later (Top level TypeOfResource only) with fixed value 'text' (LN#220)
        return None

    def _addTypeOfResource(self, modsNode):
        ## Adds exactly one typeOfResource element to the mods node.
        tor = etree.SubElement(modsNode, ("{%s}typeOfResource") % self._nsMap["mods"])
        tor.text = "text"

    ## Identifier:
    def _tlIdentifier(self, childNode):
        if len(childNode.attrib) == 0 or childNode.text is None:
            return None
        return childNode  ## Transfer 'as is'.

    ## Classification:
    def _tlClassification(self, childNode):
        if (
            not ("authority" in childNode.attrib or "authorityURI" in childNode.attrib)
            or childNode.text is None
        ):
            return None
        return childNode  ## Transfer 'as is'.

    ## Subject:
    def _tlSubject(self, childNode):
        if len(childNode.xpath("mods:topic", namespaces=self._nsMap)) < 1:
            return None
        return childNode  ## Transfer 'as is'.

    ## Extension:
    def _tlExtension(self, childNode):
        ## All <extension> tags will be removed, when returning None!
        return None

    def _getValidModsExtension(self, modsNode):
        ## Select all 'extension' child elements as separate nodes:
        extensions = modsNode.xpath(
            "self::mods:mods/mods:extension/child::*", namespaces=self._nsMap
        )
        e_rootExten = etree.Element(("{%s}extension") % self._nsMap["mods"])
        for extension in extensions:
            if self._isValidEduStandaardExtension(extension):
                e_ext = etree.SubElement(
                    e_rootExten, ("{%s}extension") % self._nsMap["mods"]
                )  # Create extension sub-element.
                # Normalize schemalocation:
                # extension.set("{http://www.w3.org/2001/XMLSchema-instance}schemaLocation", "http://www.loc.gov/mods/v3 http://www.loc.gov/standards/mods/v3/mods-"+ MODS_VERSION.replace(".", "-") +".xsd")
                e_ext.append(extension)
                e_rootExten.append(e_ext)
        return e_rootExten if len(e_rootExten) > 0 else None

    # TODO: Find out why HBO.xsd (lxml) doesnt validate, but Oxygen (Xerces) does?!?
    def _isValidEduStandaardExtension(self, lxmlNode):
        for schema, xpad, slocation in self._edu_extension_schemas:
            extent = lxmlNode.xpath(xpad, namespaces=self._nsMap)
            if len(extent) > 0:  ## Validate found EduStandaard extension:
                schema.validate(lxmlNode)
                if schema.error_log:
                    return False
                else:
                    # print "EduStandaard extension IS VALID", lxmlNode.tag
                    lxmlNode.set(
                        "{http://www.w3.org/2001/XMLSchema-instance}schemaLocation",
                        slocation,
                    )
                    return True
        ## Looped over all allowed Edustandaard extensions types: None was found...
        self.do.logMsg(self._uploadid, LOGGER2, prefix=STR_MODS)
        return False

    ## Add possible dai identifiers from daiList in Mods Extension, if some dai is not already given in the mods:name tag (as a nameIdentifier).
    ## This function is needed as long as the repositories still deliver dai identifiers in Mods Extension tag.
    ## We do NOT VALIDE the identifier, since all other nameIdentifiers are also transferred "as they are".
    def _addDaiFromModExtension(
        self, mods_node, xml_id, dailist_authority, dailist_dai_text
    ):
        if dailist_authority is not None and "dai" not in dailist_authority:
            self.do.logMsg(
                self._uploadid, LOGGER3 % (dailist_authority), prefix=STR_MODS
            )
            return
        #         Find dais from referring name element by ID:
        name = mods_node.xpath(
            "//mods:mods/mods:name[@ID='" + xml_id + "']", namespaces=self._nsMap
        )
        if len(name) > 0:
            daais = name[0].xpath(
                "self::mods:name/mods:nameIdentifier[@type='dai-nl' or @type='dai']/text()",
                namespaces=self._nsMap,
            )
            # Check if dailist_dai exists in name_nameIdentifier:
            bln_bestaatal = False
            for daai in daais:
                if dailist_dai_text.endswith(daai) or daai.endswith(dailist_dai_text):
                    bln_bestaatal = True
                    break
            if not bln_bestaatal:
                new_identifier = etree.SubElement(
                    name[0], ("{%s}nameIdentifier") % self._nsMap["mods"]
                )
                new_identifier.text = dailist_dai_text
                new_identifier.attrib["type"] = "dai-nl"
                new_identifier.attrib["typeURI"] = "info:eu-repo/dai/nl"

    def __str__(self):
        return "Normalize_nl_MODS"
